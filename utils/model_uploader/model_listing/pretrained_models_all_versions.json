[
  {
    "name": "huggingface/sentence-transformers/all-MiniLM-L12-v2",
    "versions": {
      "1.0.1": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."
      }
    }
  },
  {
    "name": "huggingface/sentence-transformers/all-MiniLM-L6-v2",
    "versions": {
      "1.0.1": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."
      }
    }
  },
  {
    "name": "huggingface/sentence-transformers/all-distilroberta-v1",
    "versions": {
      "1.0.1": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."
      }
    }
  },
  {
    "name": "huggingface/sentence-transformers/all-mpnet-base-v2",
    "versions": {
      "1.0.1": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."
      }
    }
  },
  {
    "name": "huggingface/sentence-transformers/distiluse-base-multilingual-cased-v1",
    "versions": {
      "1.0.1": {
        "format": [
          "torch_script"
        ],
        "description": "This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."
      }
    }
  },
  {
    "name": "huggingface/sentence-transformers/msmarco-distilbert-base-tas-b",
    "versions": {
      "1.0.1": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "This is a port of the DistilBert TAS-B Model to sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and is optimized for the task of semantic search."
      },
      "1.0.2": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "This is a port of the DistilBert TAS-B Model to sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and is optimized for the task of semantic search. The model version automatically truncates input to a maximum of 512 tokens."
      }
    }
  },
  {
    "name": "huggingface/sentence-transformers/multi-qa-MiniLM-L6-cos-v1",
    "versions": {
      "1.0.1": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."
      }
    }
  },
  {
    "name": "huggingface/sentence-transformers/multi-qa-mpnet-base-dot-v1",
    "versions": {
      "1.0.1": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."
      }
    }
  },
  {
    "name": "huggingface/sentence-transformers/paraphrase-MiniLM-L3-v2",
    "versions": {
      "1.0.1": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."
      }
    }
  },
  {
    "name": "huggingface/sentence-transformers/paraphrase-mpnet-base-v2",
    "versions": {
      "1.0.0": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."
      }
    }
  },
  {
    "name": "huggingface/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    "versions": {
      "1.0.1": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."
      }
    }
  },
  {
    "name": "amazon/neural-sparse/opensearch-neural-sparse-encoding-doc-v1",
    "versions": {
      "1.0.1": {
        "format": [
          "torch_script"
        ],
        "description": "This is a neural sparse encoding model: It transfers text into sparse vector, and then extract nonzero index and value to entry and weights. It serves only in ingestion and customer should use tokenizer model in query."
      }
    }
  },
  {
    "name": "huggingface/cross-encoders/ms-marco-MiniLM-L-6-v2",
    "versions": {
      "1.0.2": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order."
      }
    }
  },
  {
    "name": "huggingface/cross-encoders/ms-marco-MiniLM-L-12-v2",
    "versions": {
      "1.0.2": {
        "format": [
          "onnx",
          "torch_script"
        ],
        "description": "The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order."
      }
    }
  },
  {
    "name": "amazon/neural-sparse/opensearch-neural-sparse-encoding-doc-v2-distill",
    "versions": {
      "1.0.0": {
        "format": [
          "torch_script"
        ],
        "description": "This is a neural sparse encoding model: It transfers text into sparse vector, and then extract nonzero index and value to entry and weights. It serves only in ingestion and customer should use tokenizer model in query."
      }
    }
  },
  {
    "name": "amazon/neural-sparse/opensearch-neural-sparse-encoding-doc-v2-mini",
    "versions": {
      "1.0.0": {
        "format": [
          "torch_script"
        ],
        "description": "This is a neural sparse encoding model: It transfers text into sparse vector, and then extract nonzero index and value to entry and weights. It serves only in ingestion and customer should use tokenizer model in query."
      }
    }
  },
  {
    "name": "amazon/neural-sparse/opensearch-neural-sparse-encoding-v2-distill",
    "versions": {
      "1.0.0": {
        "format": [
          "torch_script"
        ],
        "description": "This is a neural sparse encoding model: It transfers text into sparse vector, and then extract nonzero index and value to entry and weights. It serves in both ingestion and search."
      }
    }
  }
]